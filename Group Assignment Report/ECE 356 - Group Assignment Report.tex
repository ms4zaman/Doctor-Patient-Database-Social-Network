\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[normalem]{ulem}
\usepackage[margin=1in]{geometry}
\usepackage{cancel}
\usepackage{enumerate}
\usepackage{float}
\usepackage{verbatim}
\usepackage{hyperref}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\let\Re\relax
\DeclareMathOperator{\Re}{\operatorname{Re}}
\let\Im\relax
\DeclareMathOperator{\Im}{\operatorname{Im}}

\newcommand{\blah}{blah}

\setlength\parindent{0pt}

%\includegraphics[scale=xx]{imagename}

\begin{document}

\title{ECE 356 - Database Systems Group Assignment Report}
\author{Henry Chung, Saad Zaman, Dylan Tittel}

\maketitle

\tableofcontents
\newpage

\section{Schema}
The following is the SQL DDL code that was generated by MySQL Workbench and used for the Doctor and Patient application. \\

\textbf{Note}: The password field is hashed by the insert statements. There is no hashing done on a schema. This creates a higher level of obscurity with respect to the details of our hashing. This obscurity increases the security.

\verbatiminput{res/code/createTables.sql}

\section{Changes to Design Since Deliverable 1}
One major change that was done since the initial design is the introduction of a Users table. The Users table was introduced to solve the requirement for user authentication which was neglected in the first report. The Users table is summarized in Table~\ref{tab:usersTable}.
\begin{table}[H]
	\centering
	\caption{Users Table}
	\begin{tabular}{| c | c |}
		\hline
		Field    & Type \\
		\hline
		alias    & varchar(30) \\
		password & varchar(45) \\
		level    & int \\
		\hline
	\end{tabular}
	\label{tab:usersTable}
\end{table}
The alias is the primary key of the Users table. The Doctor and Patient table are also modified slightly to have their alias foreign-key constrained to the alias of the new Users table. The level field in the Users table is defined as either a 0, 1, or 2, each determining the increasing access levels in ascending order. The currently values used for this particular application is described in Table~\ref{tab:levelsTable}.
\begin{table}[H]
	\centering
	\caption{Users Table}
	\begin{tabular}{| c | c |}
		\hline
		Level & Access Level \\
		\hline
		0 & Patient \\
		1 & Doctor \\
		2 & Administrator \\
		\hline
	\end{tabular}
	\label{tab:levelsTable}
\end{table}

\section{Third-Party Software}
MySQL Workbench was used to create and generate the SQL DDL corresponding to this specific application. \\

Otherwise stated, no unsuggested third-party software outside of what was used in the ECE 356 labs have been used for the implementation of this group assignment.

\section{Interface Design}
The GUI for the database application conforms to the model-view-controller (MVC) design pattern through a number of ways: the project structure and the semantics of the code. In an MVC architected software system, the code is separated into three major components:
\begin{itemize}
	\item Model
	\item View
	\item Controller
\end{itemize}
These three groups of components are reflected in the project layout. The views corresponds to the individual \texttt{.jsp} files found in the ``Web Pages'' folder of the project. The ``Source Packages'' section of the project contains both the models and controllers. The models are all contained with the ``models'' folder. All servlets (classes with the suffix \texttt{Servlet}) corresponds to the controller. \\

The MVC design pattern is also enforced semantically by the way the code adheres to the principle of separations of concerns (SoC). The view is strictly responsible for the presentation and templating of data. The data provided is handled by the controller and the form of the data is held in contract by the implementation of the models. The model, in general, is a Java-object representation of the tables. The controller handles obtaining the appropriate data, creating the appropriate models, and ``sending'' the models to the view. As such, every dynamic data-driven view has its own controller.

\section{Security and Access Control}
\subsection{SQL Injection Prevention}
SQL injection can occur when user-data is accepted in its raw form when building dynamic SQL statements. If the user-data is to contain malicious SQL code, then the query will be executed. This poses a security threat to database and all data stored in the database, including private data such as a user's address, are at a risk of being exposed. \\

In order to prevent SQL injection, \textit{all user-data} are first ``escaped.'' This makes it such that any SQL code in the data is now read as plain-text. In order to accomplish this, the use of Java's \texttt{PreparedStatement} class is used when building dynamic SQL that uses user-data. \\

An example of where this is done can be found in the \texttt{PatientSearchResultsServlet.java} which accepts three parameters from the user.

\verbatiminput{"res/code/SQL Injection Prevention.java"}

In this particular example, although the \texttt{provId} is passed through using a dropdown web control defined by the developer, it was still passed through and as a parameter of the \texttt{PreparedStatement} when building the dynamic SQL. This is because the security risk of a malicious user modifying the html POST data was recognized. Having every parameter go through a \texttt{PreparedStatement} accounts for this and other related risks.

\subsection{Password Hashing and Salting}
For deliverable 1 our group created stored procedures for user authentication and update password. These stored procedures are displayed below.

\verbatiminput{"res/code/sha2-userAuthentication.sql"}

This user authentication stored procedure has inputs for the userID and password which need to be authenticated against the database. The stored procedure returns an integer which simply lets the program know if the authentication passed or not. The database has two important tables which are necessary for this stored procedure. These two tables are used to store the generated salt keys and hash values unique for each userID, respectively. \\

The stored procedure above selects the generated salt from a table of stored salt keys using the passed in userID parameter and stores this value locally in a variable, vSalt. Next, the MySQL SHA2-256 command is used with the stored salt value and the passed in password parameter to generate a hash value for that user. Finally this hash value is validated against the table with the generated hash values. If the hash value for that specific userID matches then the return variable is set to 1 to indicate that the user authentication was successful, else a 0 is returned to indicate a failed user authentication.

\verbatiminput{"res/code/sha2-updatePassword.sql"}

The update password stored procedure has parameters for userID, old password, new password and a return integer to indicate whether the update password was successful or not. This stored procedure uses the same two tables which store generated salt keys and hash values for each unique userID. \\

The stored procedure above first creates local variables for the existing salt key for the userID and creates two variables for the old hash value and the new hash value. The existing salt key for the passed in userID is retrieved using a simple select statement and is stored into the local variable. The oldHash and newHash variables are set by generating the hash value using the SHA-256 command with the parameters for the old password and new password, respectively. \\

Lastly, if the oldHash variable matches the hash value in the table for that userID then the table is updated and the newHash variable replaces the existing hash value for the userID. The return integer variable is set to 1 to indicate a successful password update. If the old hash value does not match the stored value in the table the return variable is set to 0.\\

During our lab we ended up using the built in MySQL Password hashing to hash passwords, due to it being much more simple to implement, as well as allowing for the easy insertion of passwords from an automated script. We later realized how much less secure this was than the previous method, and in future we would implement the method above inorder to improve security against brute force attacks as the method above increases the obscurity of the salt. 

\subsection{Access Control}
All user authentication and security code can be found in the \texttt{LoginUtil} class. The methods contained in this utility class are as follows

\verbatiminput{"res/code/LoginUtil Prototypes.java"}

All of the methods contained in the \texttt{LoginUtil} class can be used in both the views (\texttt{.jsp} files) and controllers (\texttt{Servlet} files) in order to enforce appropriate user authentication in both the front-end and the back-end. The use of these methods in the views will prevent the user from viewing pages that they were not intended to view and the use of these methods in the controllers are to prevent the querying and binding of the respective data. \\

The \texttt{assert[User/Patient/Doctor]LoggedIn()} methods will ensure that the user logged in is of one of the specified type: logged in at all, patient, and doctor. If an assert fails, then a redirection to the login page occurs immediately to prompt user login. The \texttt{is[Patient/Doctor]LoggedIn()} methods simply returns a boolean specifying whether the check is true or false. These two methods are used to tweak certain pages in order to expose different experiences between a user who's a patient or doctor. An example of the use of these two methods can be found in the Doctor profile view where the viewing of the doctor's email is exposed only to other doctors and the option to write new review for a doctor is exposed only to patients.
\verbatiminput{"res/code/Is User Logged In.jsp"}

\section{Indexing Strategy}
The storage engine that we chose was InnoDB. We chose this storage engine as it was the default and was what we have been using throughout the majority of the ECE 356 labs. InnoDB only allows for $\mathrm{B}^+$-tree indices. \\

Indices were provided automatically for all primary and foreign keys. As a conscious design decision, these set of indices were sufficient for all queries required for the assignment. All joins were joined on these primary/foreign keys and all sorts were also performed on these keys. \\

The only possible additional index that may have been beneficial to the application would have an index on the \texttt{creationDate} in the Review table. This was not included as an index as there was an alignment with the \texttt{reviewId} and the \texttt{creationDate} in the Review table. Sorting and projecting against the \texttt{reviewId} proved to be sufficient for this application. Based on the implementation of this application, this actually performed much more efficiently. In particular, it is impossible to have equal \texttt{reviewId}s between two different rows whereas it may be possible to have the same \texttt{creationDate}s. The scenario where there are equal \texttt{creationDate}s requires more sophisticated SQL statements to obtain the same results. Performing operations on \texttt{reviewId} was both more efficient and correct.

\section{Concurrency}
Transactions are used for all page loads. We have two types of transactions:
\begin{enumerate}
	\item POST Action Transactions
	\item GET Action Transactions
\end{enumerate}
POST action transactions include Doctor and Patients searches as well as the insertions of reviews. \\

GET action transactions include the loading of profile pages and reviews as well as the user level check on all page loads. \\

We used multiple small transactions for the sake of security and modularity. In terms of security, the smaller transactions allow us to confirm permissions prior to provisioning of data. In terms of modularity, the smaller transactions allow for the same transactions to be used across multiple page keeping the indexing simpler and providing faster load times. In addition, the system has be future-proofed for features such as caching as well as the addition of new features with minimal changes to the pre-existing infrastructure. \\

The transaction isolation level that was chosen for this lab was \texttt{REPEATABLE READ}. This is the default that InnoDB uses. Only phantom reads may occur using this isolation level. Phantom reads are ok for this application because the only major changing datasets are the insertions of reviews. As a design decision, having a small amount of outdated reviews is acceptable as a trade-off for better concurrency and better performance. \\

Although there are currently no update statements in the application, a future-proof decision was made to remain in the \texttt{REPEATABLE READ} isolation level. This is because on the event that update statements are added to the application, it would make more sense from a user's perspective to \textit{miss} information versus seeing \textit{inaccurate} information. This is especially true for reviews where large decisions may be made strictly from what the user perceives. Switching to a \texttt{READ COMMITTED} isolation level would introduce non-repeatable reads. This introduces the scenario that was explained earlier. Therefore, remaining in the \texttt{REPEATABLE READ} isolation level is the better solution.

\section{Novel Features}
A novel feature unique to this group's implementation of the Doctor and Patient application can be seen on the login page. The application's name, DocHunt!, is a play on words of the popular retro game Duck Hunt. As such, certain themes from the game Duck Hunt were used and integrated into the login page of the Doctor and Patient application. Figure~\ref{fig:docHuntLogin} illustrates the login page.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{"res/image/DocHunt Login Page"}
	\caption{The Login Page for DocHunt!}
	\label{fig:docHuntLogin}
\end{figure}

\end{document}